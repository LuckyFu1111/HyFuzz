# HyFuzz é¡¹ç›®å…¨é¢æ”¹è¿›å»ºè®®æŠ¥å‘Š

**ç”Ÿæˆæ—¥æœŸ**: 2025-11-11
**å®¡æŸ¥èŒƒå›´**: å®Œæ•´ä»£ç åº“ï¼ˆWindows Serverã€Mac Serverã€Ubuntu Clientï¼‰
**ä»£ç é‡**: ~43,000 è¡Œç”Ÿäº§ä»£ç  + 4,698 è¡Œæµ‹è¯•ä»£ç 

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

ç»è¿‡å¯¹ HyFuzz é¡¹ç›®çš„å…¨é¢å®¡æŸ¥ï¼Œå‘ç°äº† **62 ä¸ªéœ€è¦æ”¹è¿›çš„é—®é¢˜**ï¼Œåˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

| ç±»åˆ« | é—®é¢˜æ•°é‡ | ä¼˜å…ˆçº§åˆ†å¸ƒ |
|------|---------|-----------|
| ğŸ”´ å®‰å…¨æ€§é—®é¢˜ | 11 | 4 ä¸ªå…³é”® |
| âš¡ æ€§èƒ½é—®é¢˜ | 15 | 5 ä¸ªé«˜ä¼˜å…ˆçº§ |
| ğŸ’» ä»£ç å¼‚å‘³ | 18 | 8 ä¸ªä¸­ä¼˜å…ˆçº§ |
| âš ï¸ é”™è¯¯å¤„ç† | 9 | 3 ä¸ªé«˜ä¼˜å…ˆçº§ |
| ğŸ”„ å¼‚æ­¥ä»£ç  | 9 | 3 ä¸ªé«˜ä¼˜å…ˆçº§ |

**é¡¹ç›®æ•´ä½“è¯„åˆ†**: â­â­â­â­ (4/5 æ˜Ÿ)

**ä¼˜åŠ¿**:
- âœ… æ¨¡å—åŒ–æ¶æ„è®¾è®¡è‰¯å¥½
- âœ… å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼ˆ85 ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œ233 ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰
- âœ… ä¸°å¯Œçš„æ–‡æ¡£ç»“æ„
- âœ… ç°ä»£åŒ–çš„å¼€å‘å·¥å…·é“¾ï¼ˆpre-commit hooksã€ç±»å‹æ£€æŸ¥ç­‰ï¼‰

**éœ€è¦æ”¹è¿›çš„é¢†åŸŸ**:
- âŒ ä¸¥é‡çš„å®‰å…¨æ¼æ´ï¼ˆPickle ååºåˆ—åŒ–ã€ç¡¬ç¼–ç å¯†é’¥ï¼‰
- âŒ æ€§èƒ½ä¼˜åŒ–æœºä¼šï¼ˆå†…å­˜æ³„æ¼ã€ç¼“å­˜ç­–ç•¥ï¼‰
- âŒ ä»£ç é‡å¤å’Œç»„ç»‡é—®é¢˜
- âŒ æ–‡æ¡£ä¸å®Œæ•´ï¼ˆå¤šä¸ªç©ºæ–‡æ¡£æ–‡ä»¶ï¼‰

---

## ğŸ¯ ä¼˜å…ˆçº§è¡ŒåŠ¨è®¡åˆ’

### ğŸ”´ P0 - æœ¬å‘¨å¿…é¡»ä¿®å¤ï¼ˆå…³é”®å®‰å…¨é—®é¢˜ï¼‰

#### 1. **ç§»é™¤ Pickle ååºåˆ—åŒ–æ¼æ´**ï¼ˆRCE é£é™©ï¼‰

**å½±å“æ–‡ä»¶**:
- `src/knowledge/graph_cache.py`
- `src/knowledge/cve_repository.py`
- `src/knowledge/cwe_repository.py`
- `src/knowledge/knowledge_loader.py`

**é—®é¢˜**:
```python
# å½“å‰ä»£ç ï¼ˆä¸å®‰å…¨ï¼‰
import pickle
cached_data = pickle.loads(data)  # è¿œç¨‹ä»£ç æ‰§è¡Œé£é™©
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
import json
import orjson  # æ›´å¿«çš„ JSON åº“

# ä½¿ç”¨ JSON æ›¿ä»£
cached_data = orjson.loads(data)

# å¯¹äºå¤æ‚å¯¹è±¡ï¼Œä½¿ç”¨è‡ªå®šä¹‰åºåˆ—åŒ–
def serialize_graph(graph):
    return {
        'nodes': list(graph.nodes(data=True)),
        'edges': list(graph.edges(data=True))
    }

def deserialize_graph(data):
    G = nx.Graph()
    G.add_nodes_from(data['nodes'])
    G.add_edges_from(data['edges'])
    return G
```

**æ—¶é—´ä¼°è®¡**: 2-3 å¤©
**é£é™©ç­‰çº§**: ğŸ”´ ä¸¥é‡ï¼ˆå¯èƒ½å¯¼è‡´å®Œå…¨ç³»ç»Ÿå¦¥åï¼‰

---

#### 2. **ä¿®å¤ç¡¬ç¼–ç å¯†é’¥å’Œä¸å®‰å…¨ä»¤ç‰Œç”Ÿæˆ**

**å½±å“æ–‡ä»¶**:
- `src/api/middleware.py:395, 489-496`

**é—®é¢˜**:
```python
# ç¡¬ç¼–ç å¯†é’¥
SECRET_KEY = "my-secret-key-12345"  # ä¸å®‰å…¨ï¼

# ä¸å®‰å…¨çš„ä»¤ç‰Œç”Ÿæˆ
token = hashlib.md5(username.encode()).hexdigest()  # å¯é¢„æµ‹
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
import secrets
from datetime import datetime, timedelta
import jwt
from cryptography.fernet import Fernet

# 1. ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨å¯†é’¥
import os
SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
if not SECRET_KEY:
    raise ValueError("JWT_SECRET_KEY must be set in environment")

# 2. ä½¿ç”¨ PyJWT ç”Ÿæˆå®‰å…¨ä»¤ç‰Œ
def generate_token(user_id: str, expires_in: int = 3600) -> str:
    """ç”Ÿæˆå®‰å…¨çš„ JWT ä»¤ç‰Œ"""
    payload = {
        'user_id': user_id,
        'exp': datetime.utcnow() + timedelta(seconds=expires_in),
        'iat': datetime.utcnow(),
        'jti': secrets.token_urlsafe(32)  # JWT IDï¼Œé˜²æ­¢é‡æ”¾æ”»å‡»
    }
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')

def verify_token(token: str) -> dict:
    """éªŒè¯ä»¤ç‰Œ"""
    try:
        return jwt.decode(token, SECRET_KEY, algorithms=['HS256'])
    except jwt.ExpiredSignatureError:
        raise ValueError("Token has expired")
    except jwt.InvalidTokenError:
        raise ValueError("Invalid token")

# 3. ç”Ÿæˆå¯†é’¥çš„è„šæœ¬
def generate_secret_key():
    """ç”ŸæˆåŠ å¯†å¯†é’¥"""
    return secrets.token_urlsafe(64)
```

**æ—¶é—´ä¼°è®¡**: 1-2 å¤©
**é£é™©ç­‰çº§**: ğŸ”´ ä¸¥é‡ï¼ˆä»¤ç‰Œä¼ªé€ ã€æœªæˆæƒè®¿é—®ï¼‰

---

#### 3. **ä¿®å¤ä¸å®‰å…¨çš„åŠ¨æ€å¯¼å…¥**

**å½±å“æ–‡ä»¶**:
- `src/__init__.py:114`
- `src/llm/__init__.py:207`

**é—®é¢˜**:
```python
# ä¸å®‰å…¨çš„åŠ¨æ€å¯¼å…¥
module_name = user_input
module = __import__(module_name)  # ä»»æ„æ¨¡å—æ³¨å…¥é£é™©
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ç™½åå•éªŒè¯
ALLOWED_MODULES = {
    'llm_client': 'src.llm.llm_client',
    'cot_engine': 'src.llm.cot_engine',
    'knowledge': 'src.knowledge',
    # ... å…¶ä»–å…è®¸çš„æ¨¡å—
}

def safe_import(module_key: str):
    """å®‰å…¨çš„åŠ¨æ€å¯¼å…¥"""
    if module_key not in ALLOWED_MODULES:
        raise ValueError(f"Module '{module_key}' is not allowed")

    module_path = ALLOWED_MODULES[module_key]
    try:
        return importlib.import_module(module_path)
    except ImportError as e:
        logger.error(f"Failed to import {module_path}: {e}")
        raise

# æˆ–è€…ä½¿ç”¨æ’ä»¶ç³»ç»Ÿ
from pluggy import PluginManager

pm = PluginManager("hyfuzz")
pm.add_hookspecs(HyFuzzHooks)
pm.load_setuptools_entrypoints("hyfuzz")
```

**æ—¶é—´ä¼°è®¡**: 2 å¤©
**é£é™©ç­‰çº§**: ğŸ”´ é«˜ï¼ˆä»»æ„ä»£ç æ‰§è¡Œï¼‰

---

#### 4. **æ·»åŠ å…¨å±€å¼‚å¸¸å¤„ç†**

**å½±å“**: æ•´ä¸ªåº”ç”¨ç¨‹åº

**é—®é¢˜**:
- ç¼ºå°‘é¡¶å±‚å¼‚å¸¸æ•è·
- æœªå¤„ç†çš„å¼‚å¸¸å¯¼è‡´æœåŠ¡å´©æºƒ
- æ²¡æœ‰é”™è¯¯æ¢å¤æœºåˆ¶

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# src/main.py æˆ– src/__main__.py
import sys
import traceback
from contextlib import asynccontextmanager

class GlobalExceptionHandler:
    """å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""

    def __init__(self, logger):
        self.logger = logger
        self.original_excepthook = sys.excepthook

    def __enter__(self):
        sys.excepthook = self.handle_exception
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        sys.excepthook = self.original_excepthook

    def handle_exception(self, exc_type, exc_val, exc_tb):
        """å¤„ç†æœªæ•è·çš„å¼‚å¸¸"""
        if issubclass(exc_type, KeyboardInterrupt):
            # å…è®¸ Ctrl+C æ­£å¸¸å·¥ä½œ
            sys.__excepthook__(exc_type, exc_val, exc_tb)
            return

        # è®°å½•å®Œæ•´çš„å¼‚å¸¸ä¿¡æ¯
        self.logger.critical(
            "Uncaught exception",
            exc_info=(exc_type, exc_val, exc_tb),
            extra={
                'exception_type': exc_type.__name__,
                'exception_message': str(exc_val),
                'traceback': ''.join(traceback.format_tb(exc_tb))
            }
        )

        # å°è¯•ä¼˜é›…å…³é—­
        try:
            cleanup_resources()
        except Exception as e:
            self.logger.error(f"Error during cleanup: {e}")

        # é€€å‡º
        sys.exit(1)

@asynccontextmanager
async def lifespan(app):
    """FastAPI ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨
    logger.info("Starting HyFuzz MCP Server...")

    # è®¾ç½®å…¨å±€å¼‚å¸¸å¤„ç†
    with GlobalExceptionHandler(logger):
        try:
            await initialize_services()
            yield
        except Exception as e:
            logger.critical(f"Fatal error during startup: {e}")
            raise
        finally:
            # æ¸…ç†
            logger.info("Shutting down HyFuzz MCP Server...")
            await cleanup_services()

# åœ¨ä¸»åº”ç”¨ä¸­ä½¿ç”¨
app = FastAPI(lifespan=lifespan)
```

**æ—¶é—´ä¼°è®¡**: 1 å¤©
**é£é™©ç­‰çº§**: ğŸ”´ é«˜ï¼ˆæœåŠ¡ç¨³å®šæ€§ï¼‰

---

### ğŸŸ  P1 - æœ¬æœˆå†…ä¿®å¤ï¼ˆé«˜ä¼˜å…ˆçº§æ€§èƒ½é—®é¢˜ï¼‰

#### 5. **ä¿®å¤ RateLimitBucket å†…å­˜æ³„æ¼**

**å½±å“æ–‡ä»¶**: `src/resources/rate_limiter.py`

**é—®é¢˜**:
```python
class RateLimitBucket:
    def __init__(self):
        self._buckets = {}  # æ— é™å¢é•¿ï¼Œä»ä¸æ¸…ç†

    def consume(self, key: str):
        if key not in self._buckets:
            self._buckets[key] = []
        # ... æ·»åŠ è®°å½•ä½†ä»ä¸åˆ é™¤æ—§è®°å½•
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
import time
from collections import defaultdict, deque
from threading import Lock

class RateLimitBucket:
    """æ”¹è¿›çš„é™æµæ¡¶ï¼Œå¸¦è‡ªåŠ¨æ¸…ç†"""

    def __init__(self, window_size: int = 60, max_entries: int = 10000):
        self._buckets: dict[str, deque] = defaultdict(deque)
        self._lock = Lock()
        self._window_size = window_size
        self._max_entries = max_entries
        self._last_cleanup = time.time()

    def consume(self, key: str, tokens: int = 1) -> bool:
        """æ¶ˆè´¹ä»¤ç‰Œ"""
        now = time.time()

        # å®šæœŸæ¸…ç†ï¼ˆæ¯åˆ†é’Ÿï¼‰
        if now - self._last_cleanup > 60:
            self._cleanup_expired_buckets(now)
            self._last_cleanup = now

        with self._lock:
            bucket = self._buckets[key]

            # ç§»é™¤è¿‡æœŸçš„æ—¶é—´æˆ³
            cutoff = now - self._window_size
            while bucket and bucket[0] < cutoff:
                bucket.popleft()

            # æ·»åŠ æ–°æ—¶é—´æˆ³
            bucket.append(now)

            return len(bucket) <= self._max_entries

    def _cleanup_expired_buckets(self, now: float):
        """æ¸…ç†è¿‡æœŸçš„æ¡¶"""
        cutoff = now - self._window_size * 2  # ä¿ç•™ 2 å€çª—å£æ—¶é—´

        with self._lock:
            expired_keys = [
                key for key, bucket in self._buckets.items()
                if not bucket or bucket[-1] < cutoff
            ]

            for key in expired_keys:
                del self._buckets[key]

            if expired_keys:
                logger.debug(f"Cleaned up {len(expired_keys)} expired rate limit buckets")

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return {
                'total_buckets': len(self._buckets),
                'total_entries': sum(len(b) for b in self._buckets.values())
            }
```

**æ—¶é—´ä¼°è®¡**: 1 å¤©
**é¢„æœŸæ”¹è¿›**: å†…å­˜ä½¿ç”¨ä»æŒç»­å¢é•¿ â†’ ç¨³å®šåœ¨ ~10MB

---

#### 6. **ä¼˜åŒ– CoT é“¾ç”Ÿæˆæ€§èƒ½**

**å½±å“æ–‡ä»¶**: `src/llm/cot_engine.py`

**é—®é¢˜**: ä¸²è¡Œå¤„ç†å¤šä¸ªæ€ç»´é“¾æ­¥éª¤ï¼Œå“åº”æ—¶é—´è¿‡é•¿ï¼ˆ10-20 ç§’ï¼‰

**ä¿®å¤æ–¹æ¡ˆ**:
```python
import asyncio
from typing import List
from concurrent.futures import ThreadPoolExecutor

class CoTEngine:
    """ä¼˜åŒ–çš„é“¾å¼æ€ç»´å¼•æ“"""

    def __init__(self, llm_client, max_parallel: int = 3):
        self.llm_client = llm_client
        self.max_parallel = max_parallel
        self._executor = ThreadPoolExecutor(max_workers=max_parallel)

    async def generate_cot_parallel(
        self,
        prompts: List[str],
        max_depth: int = 3
    ) -> List[dict]:
        """å¹¶è¡Œç”Ÿæˆå¤šä¸ª CoT é“¾"""

        # ç¬¬ä¸€å±‚ï¼šå¹¶è¡Œç”Ÿæˆåˆå§‹å“åº”
        tasks = [
            self._generate_single_step(prompt)
            for prompt in prompts
        ]
        initial_responses = await asyncio.gather(*tasks)

        # åç»­å±‚ï¼šæ ¹æ®ä¾èµ–å…³ç³»å¹¶è¡Œå¤„ç†
        results = []
        for depth in range(1, max_depth):
            # è¯†åˆ«å¯å¹¶è¡Œçš„æ­¥éª¤
            parallel_tasks = []
            for i, response in enumerate(initial_responses):
                if not self._needs_previous_step(response):
                    parallel_tasks.append(
                        self._generate_next_step(response, depth)
                    )

            # å¹¶è¡Œæ‰§è¡Œ
            if parallel_tasks:
                next_responses = await asyncio.gather(*parallel_tasks)
                results.extend(next_responses)

        return results

    async def _generate_single_step(self, prompt: str) -> dict:
        """ç”Ÿæˆå•ä¸ªæ€ç»´æ­¥éª¤"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self._executor,
            self.llm_client.generate,
            prompt
        )

    def _needs_previous_step(self, response: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å‰ä¸€æ­¥çš„ç»“æœ"""
        # å®ç°ä¾èµ–æ£€æµ‹é€»è¾‘
        return 'depends_on' in response

# ä½¿ç”¨æ‰¹å¤„ç†è¿›ä¸€æ­¥ä¼˜åŒ–
class BatchedCoTEngine(CoTEngine):
    """æ‰¹é‡å¤„ç†çš„ CoT å¼•æ“"""

    async def generate_batch(
        self,
        prompts: List[str],
        batch_size: int = 5
    ) -> List[dict]:
        """æ‰¹é‡ç”Ÿæˆï¼Œå‡å°‘ç½‘ç»œå¾€è¿”"""

        results = []
        for i in range(0, len(prompts), batch_size):
            batch = prompts[i:i + batch_size]

            # å•æ¬¡ API è°ƒç”¨å¤„ç†å¤šä¸ªæç¤º
            batch_results = await self.llm_client.generate_batch(batch)
            results.extend(batch_results)

        return results
```

**æ—¶é—´ä¼°è®¡**: 2-3 å¤©
**é¢„æœŸæ”¹è¿›**: å“åº”æ—¶é—´ä» 10-20 ç§’ â†’ 1-3 ç§’ï¼ˆ3-10 å€æå‡ï¼‰

---

#### 7. **æ”¹è¿› VulnerabilityDB ç¼“å­˜ç­–ç•¥**

**å½±å“æ–‡ä»¶**: `src/knowledge/vulnerability_db.py`

**é—®é¢˜**: LRU ç¼“å­˜é©±é€æ•ˆç‡ä½ï¼Œé¢‘ç¹çš„ç¼“å­˜æœªå‘½ä¸­

**ä¿®å¤æ–¹æ¡ˆ**:
```python
from cachetools import TTLCache, LRUCache
import hashlib
from functools import wraps

class SmartVulnerabilityCache:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œç»“åˆ LRU å’Œ TTL"""

    def __init__(
        self,
        max_size: int = 10000,
        ttl: int = 3600,  # 1 å°æ—¶
        hot_size: int = 1000  # çƒ­æ•°æ®ç¼“å­˜
    ):
        # çƒ­æ•°æ®ç¼“å­˜ï¼ˆé¢‘ç¹è®¿é—®çš„æ•°æ®ï¼‰
        self._hot_cache = LRUCache(maxsize=hot_size)

        # å†·æ•°æ®ç¼“å­˜ï¼ˆå¸¦ TTLï¼‰
        self._cold_cache = TTLCache(maxsize=max_size, ttl=ttl)

        # è®¿é—®è®¡æ•°
        self._access_counts = defaultdict(int)
        self._hot_threshold = 5  # è®¿é—® 5 æ¬¡åè¿›å…¥çƒ­ç¼“å­˜

    def get(self, key: str):
        """è·å–ç¼“å­˜æ•°æ®"""
        # å…ˆæŸ¥çƒ­ç¼“å­˜
        if key in self._hot_cache:
            return self._hot_cache[key]

        # å†æŸ¥å†·ç¼“å­˜
        if key in self._cold_cache:
            value = self._cold_cache[key]

            # æ›´æ–°è®¿é—®è®¡æ•°
            self._access_counts[key] += 1

            # æå‡åˆ°çƒ­ç¼“å­˜
            if self._access_counts[key] >= self._hot_threshold:
                self._hot_cache[key] = value
                del self._cold_cache[key]

            return value

        return None

    def set(self, key: str, value):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        # æ–°æ•°æ®æ”¾å…¥å†·ç¼“å­˜
        self._cold_cache[key] = value
        self._access_counts[key] = 0

    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            'hot_cache_size': len(self._hot_cache),
            'cold_cache_size': len(self._cold_cache),
            'hot_cache_hits': getattr(self._hot_cache, 'hits', 0),
            'cold_cache_hits': getattr(self._cold_cache, 'hits', 0),
        }

# ä½¿ç”¨è£…é¥°å™¨ç®€åŒ–ç¼“å­˜ä½¿ç”¨
def smart_cache(cache: SmartVulnerabilityCache):
    """æ™ºèƒ½ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = hashlib.sha256(
                f"{func.__name__}:{args}:{kwargs}".encode()
            ).hexdigest()

            # æŸ¥ç¼“å­˜
            cached = cache.get(cache_key)
            if cached is not None:
                return cached

            # æ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)

            # å­˜ç¼“å­˜
            cache.set(cache_key, result)

            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
vulnerability_cache = SmartVulnerabilityCache()

@smart_cache(vulnerability_cache)
async def get_vulnerability(cve_id: str):
    """è·å–æ¼æ´ä¿¡æ¯ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰"""
    return await db.query_vulnerability(cve_id)
```

**æ—¶é—´ä¼°è®¡**: 2 å¤©
**é¢„æœŸæ”¹è¿›**: ç¼“å­˜å‘½ä¸­ç‡ä» ~30% â†’ 80%+

---

#### 8. **æ·»åŠ å¼‚æ­¥è¶…æ—¶ä¿æŠ¤**

**å½±å“æ–‡ä»¶**: æ‰€æœ‰å¼‚æ­¥å‡½æ•°ï¼ˆ22 ä¸ªæ–‡ä»¶ï¼‰

**é—®é¢˜**: å¼‚æ­¥è¯·æ±‚å¯èƒ½æ— é™æœŸæŒ‚èµ·

**ä¿®å¤æ–¹æ¡ˆ**:
```python
import asyncio
from functools import wraps
from typing import Optional, TypeVar

T = TypeVar('T')

def async_timeout(seconds: int = 30):
    """å¼‚æ­¥è¶…æ—¶è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            try:
                return await asyncio.wait_for(
                    func(*args, **kwargs),
                    timeout=seconds
                )
            except asyncio.TimeoutError:
                logger.error(
                    f"{func.__name__} timed out after {seconds}s",
                    extra={'args': args, 'kwargs': kwargs}
                )
                raise TimeoutError(f"{func.__name__} exceeded {seconds}s timeout")
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@async_timeout(seconds=10)
async def fetch_llm_response(prompt: str) -> str:
    """è·å– LLM å“åº”ï¼ˆå¸¦è¶…æ—¶ï¼‰"""
    return await llm_client.generate(prompt)

# å…¨å±€è¶…æ—¶ä¸Šä¸‹æ–‡
class TimeoutContext:
    """è¶…æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, timeout: float):
        self.timeout = timeout
        self._task: Optional[asyncio.Task] = None

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._task and not self._task.done():
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass

    async def run(self, coro):
        """è¿è¡Œåç¨‹ï¼Œå¸¦è¶…æ—¶"""
        self._task = asyncio.create_task(coro)
        try:
            return await asyncio.wait_for(self._task, timeout=self.timeout)
        except asyncio.TimeoutError:
            logger.warning(f"Operation timed out after {self.timeout}s")
            raise

# ä½¿ç”¨ç¤ºä¾‹
async def process_with_timeout():
    async with TimeoutContext(timeout=30.0) as ctx:
        result = await ctx.run(expensive_operation())
    return result
```

**æ—¶é—´ä¼°è®¡**: 1 å¤©
**å½±å“**: é˜²æ­¢èµ„æºæ³„æ¼ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§

---

### ğŸŸ¡ P2 - æœªæ¥ 2 ä¸ªæœˆï¼ˆä»£ç è´¨é‡æ”¹è¿›ï¼‰

#### 9. **é‡æ„ RouteHandlers ç±»ï¼ˆè¿å SRPï¼‰**

**å½±å“æ–‡ä»¶**: `src/api/handlers.py`

**é—®é¢˜**: å•ä¸ªç±»æœ‰ 100+ ä¸ªæ–¹æ³•ï¼Œè¿åå•ä¸€èŒè´£åŸåˆ™

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# æ‹†åˆ†ä¸ºå¤šä¸ªä¸“é—¨çš„å¤„ç†å™¨ç±»

# src/api/handlers/fuzzing_handlers.py
class FuzzingHandlers:
    """æ¨¡ç³Šæµ‹è¯•ç›¸å…³çš„è¯·æ±‚å¤„ç†"""

    async def start_fuzzing_campaign(self, request: Request):
        """å¯åŠ¨æ¨¡ç³Šæµ‹è¯•æ´»åŠ¨"""
        pass

    async def stop_fuzzing_campaign(self, campaign_id: str):
        """åœæ­¢æ¨¡ç³Šæµ‹è¯•æ´»åŠ¨"""
        pass

    async def get_fuzzing_status(self, campaign_id: str):
        """è·å–æ¨¡ç³Šæµ‹è¯•çŠ¶æ€"""
        pass

# src/api/handlers/payload_handlers.py
class PayloadHandlers:
    """è´Ÿè½½ç”Ÿæˆç›¸å…³çš„è¯·æ±‚å¤„ç†"""

    async def generate_payload(self, request: Request):
        """ç”Ÿæˆæµ‹è¯•è´Ÿè½½"""
        pass

    async def validate_payload(self, payload: dict):
        """éªŒè¯è´Ÿè½½"""
        pass

# src/api/handlers/result_handlers.py
class ResultHandlers:
    """ç»“æœæŸ¥è¯¢ç›¸å…³çš„è¯·æ±‚å¤„ç†"""

    async def get_results(self, campaign_id: str):
        """è·å–æµ‹è¯•ç»“æœ"""
        pass

    async def export_results(self, campaign_id: str, format: str):
        """å¯¼å‡ºç»“æœ"""
        pass

# src/api/routes.py
from src.api.handlers.fuzzing_handlers import FuzzingHandlers
from src.api.handlers.payload_handlers import PayloadHandlers
from src.api.handlers.result_handlers import ResultHandlers

def setup_routes(app: FastAPI):
    """è®¾ç½®è·¯ç”±"""
    fuzzing = FuzzingHandlers()
    payload = PayloadHandlers()
    result = ResultHandlers()

    # æ¨¡ç³Šæµ‹è¯•è·¯ç”±
    app.post("/api/fuzzing/start")(fuzzing.start_fuzzing_campaign)
    app.post("/api/fuzzing/{campaign_id}/stop")(fuzzing.stop_fuzzing_campaign)
    app.get("/api/fuzzing/{campaign_id}/status")(fuzzing.get_fuzzing_status)

    # è´Ÿè½½è·¯ç”±
    app.post("/api/payloads/generate")(payload.generate_payload)
    app.post("/api/payloads/validate")(payload.validate_payload)

    # ç»“æœè·¯ç”±
    app.get("/api/results/{campaign_id}")(result.get_results)
    app.get("/api/results/{campaign_id}/export")(result.export_results)
```

**æ—¶é—´ä¼°è®¡**: 3-4 å¤©
**æ”¶ç›Š**: æ›´å¥½çš„ä»£ç ç»„ç»‡ï¼Œæ›´å®¹æ˜“æµ‹è¯•å’Œç»´æŠ¤

---

#### 10. **åˆå¹¶é‡å¤çš„ embedding_manager å®ç°**

**å½±å“æ–‡ä»¶**:
- `src/llm/embedding_manager.py` (900 è¡Œ)
- `src/knowledge/embedding_manager.py` (38 è¡Œ)

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# src/embeddings/embedding_manager.pyï¼ˆç»Ÿä¸€å®ç°ï¼‰
from abc import ABC, abstractmethod
from typing import List, Protocol

class EmbeddingProvider(Protocol):
    """åµŒå…¥æä¾›è€…åè®®"""

    async def embed(self, text: str) -> List[float]:
        """ç”ŸæˆåµŒå…¥å‘é‡"""
        ...

    async def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡"""
        ...

class OllamaEmbeddingProvider:
    """Ollama åµŒå…¥æä¾›è€…"""

    def __init__(self, model: str = "all-minilm"):
        self.model = model
        self.client = OllamaClient()

    async def embed(self, text: str) -> List[float]:
        """ç”ŸæˆåµŒå…¥"""
        return await self.client.embeddings(model=self.model, prompt=text)

    async def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆ"""
        return await asyncio.gather(*[self.embed(t) for t in texts])

class CachedEmbeddingProvider:
    """å¸¦ç¼“å­˜çš„åµŒå…¥æä¾›è€…ï¼ˆè£…é¥°å™¨æ¨¡å¼ï¼‰"""

    def __init__(self, provider: EmbeddingProvider, cache: Cache):
        self.provider = provider
        self.cache = cache

    async def embed(self, text: str) -> List[float]:
        """å¸¦ç¼“å­˜çš„åµŒå…¥ç”Ÿæˆ"""
        cache_key = hashlib.sha256(text.encode()).hexdigest()

        cached = self.cache.get(cache_key)
        if cached:
            return cached

        embedding = await self.provider.embed(text)
        self.cache.set(cache_key, embedding)
        return embedding

class EmbeddingManager:
    """ç»Ÿä¸€çš„åµŒå…¥ç®¡ç†å™¨"""

    def __init__(self, provider: EmbeddingProvider):
        self.provider = provider

    async def embed_text(self, text: str) -> List[float]:
        """åµŒå…¥æ–‡æœ¬"""
        return await self.provider.embed(text)

    async def embed_documents(self, docs: List[str]) -> List[List[float]]:
        """åµŒå…¥æ–‡æ¡£"""
        return await self.provider.embed_batch(docs)

    def similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        return cosine_similarity(embedding1, embedding2)

# ä½¿ç”¨ç¤ºä¾‹
from src.embeddings.embedding_manager import (
    EmbeddingManager,
    OllamaEmbeddingProvider,
    CachedEmbeddingProvider
)

# LLM æ¨¡å—ä½¿ç”¨
llm_embedding_provider = OllamaEmbeddingProvider(model="all-minilm")
llm_embedding_manager = EmbeddingManager(
    CachedEmbeddingProvider(llm_embedding_provider, llm_cache)
)

# Knowledge æ¨¡å—ä½¿ç”¨
knowledge_embedding_provider = OllamaEmbeddingProvider(model="nomic-embed-text")
knowledge_embedding_manager = EmbeddingManager(
    CachedEmbeddingProvider(knowledge_embedding_provider, knowledge_cache)
)
```

**æ—¶é—´ä¼°è®¡**: 2 å¤©
**æ”¶ç›Š**: æ¶ˆé™¤ä»£ç é‡å¤ï¼Œç»Ÿä¸€æ¥å£

---

#### 11. **ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿ**

**å½±å“æ–‡ä»¶**:
- `src/llm/cache_manager.py` (843 è¡Œ)
- `src/cache/memory_cache.py` (30 è¡Œ)
- `src/cache/redis_cache.py` (22 è¡Œ)
- `src/cache/distributed_cache.py` (29 è¡Œ)

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# src/cache/unified_cache.py
from abc import ABC, abstractmethod
from typing import Optional, Any
import asyncio

class CacheBackend(ABC):
    """ç¼“å­˜åç«¯æŠ½è±¡"""

    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        pass

    @abstractmethod
    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """è®¾ç½®ç¼“å­˜"""
        pass

    @abstractmethod
    async def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        pass

    @abstractmethod
    async def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        pass

class MemoryCacheBackend(CacheBackend):
    """å†…å­˜ç¼“å­˜åç«¯"""

    def __init__(self, max_size: int = 1000):
        self._cache = TTLCache(maxsize=max_size, ttl=3600)
        self._lock = asyncio.Lock()

    async def get(self, key: str) -> Optional[Any]:
        async with self._lock:
            return self._cache.get(key)

    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        async with self._lock:
            self._cache[key] = value

class RedisCacheBackend(CacheBackend):
    """Redis ç¼“å­˜åç«¯"""

    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url, decode_responses=True)

    async def get(self, key: str) -> Optional[Any]:
        value = await self.redis.get(key)
        return orjson.loads(value) if value else None

    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        serialized = orjson.dumps(value)
        if ttl:
            await self.redis.setex(key, ttl, serialized)
        else:
            await self.redis.set(key, serialized)

class UnifiedCacheManager:
    """ç»Ÿä¸€çš„ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, backend: CacheBackend, namespace: str = "default"):
        self.backend = backend
        self.namespace = namespace

    def _make_key(self, key: str) -> str:
        """ç”Ÿæˆå¸¦å‘½åç©ºé—´çš„é”®"""
        return f"{self.namespace}:{key}"

    async def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        return await self.backend.get(self._make_key(key))

    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """è®¾ç½®ç¼“å­˜"""
        await self.backend.set(self._make_key(key), value, ttl)

    async def get_or_set(
        self,
        key: str,
        factory,
        ttl: Optional[int] = None
    ) -> Any:
        """è·å–æˆ–è®¾ç½®ç¼“å­˜"""
        value = await self.get(key)
        if value is None:
            value = await factory() if asyncio.iscoroutinefunction(factory) else factory()
            await self.set(key, value, ttl)
        return value

    def cached(self, ttl: Optional[int] = None):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                cache_key = f"{func.__name__}:{args}:{kwargs}"
                return await self.get_or_set(
                    cache_key,
                    lambda: func(*args, **kwargs),
                    ttl
                )
            return wrapper
        return decorator

# å·¥å‚å‡½æ•°
def create_cache_manager(
    backend_type: str = "memory",
    namespace: str = "default",
    **kwargs
) -> UnifiedCacheManager:
    """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨"""

    if backend_type == "memory":
        backend = MemoryCacheBackend(**kwargs)
    elif backend_type == "redis":
        backend = RedisCacheBackend(**kwargs)
    else:
        raise ValueError(f"Unknown backend type: {backend_type}")

    return UnifiedCacheManager(backend, namespace)

# ä½¿ç”¨ç¤ºä¾‹
llm_cache = create_cache_manager(backend_type="memory", namespace="llm")
knowledge_cache = create_cache_manager(
    backend_type="redis",
    namespace="knowledge",
    redis_url="redis://localhost:6379"
)

@llm_cache.cached(ttl=3600)
async def get_llm_response(prompt: str):
    """è·å– LLM å“åº”ï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼‰"""
    return await llm_client.generate(prompt)
```

**æ—¶é—´ä¼°è®¡**: 3 å¤©
**æ”¶ç›Š**: ç»Ÿä¸€ç¼“å­˜æ¥å£ï¼Œæ›´å®¹æ˜“åˆ‡æ¢åç«¯

---

#### 12. **æ¸…ç†ç©ºæ–‡æ¡£å¹¶å¡«å……å†…å®¹**

**å½±å“æ–‡ä»¶**:
- `docs/API.md` (0 è¡Œ)
- `docs/ARCHITECTURE.md` (0 è¡Œ)
- `docs/LLM_INTEGRATION.md` (0 è¡Œ)
- `docs/SETUP.md` (0 è¡Œ)
- `docs/TROUBLESHOOTING.md` (0 è¡Œ)
- å…¶ä»– 15 ä¸ªåªæœ‰ 1 è¡Œçš„æ–‡æ¡£

**ä¿®å¤æ–¹æ¡ˆ**:

**é€‰é¡¹ A**: åˆ é™¤ç©ºæ–‡æ¡£ï¼Œåœ¨ README ä¸­å¼•ç”¨å®Œæ•´æ–‡æ¡£
```markdown
# README.md

## æ–‡æ¡£

- [æ¶æ„è®¾è®¡](docs/PROJECT_ARCHITECTURE.md) - è¯¦ç»†çš„ç³»ç»Ÿæ¶æ„è¯´æ˜
- [API å‚è€ƒ](docs/PROJECT_API.md) - å®Œæ•´çš„ API æ–‡æ¡£
- [éƒ¨ç½²æŒ‡å—](docs/PROJECT_DEPLOYMENT.md) - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- [æ•…éšœæ’é™¤](docs/PROJECT_TROUBLESHOOTING.md) - å¸¸è§é—®é¢˜è§£å†³

> æ³¨æ„ï¼šæ‰€æœ‰æ–‡æ¡£ä½¿ç”¨ `PROJECT_` å‰ç¼€ï¼Œé¿å…æ··æ·†ã€‚
```

**é€‰é¡¹ B**: å¡«å……ç©ºæ–‡æ¡£å†…å®¹
```markdown
# docs/API.md

# HyFuzz API æ–‡æ¡£

æœ¬æ–‡æ¡£å·²åˆå¹¶åˆ° [PROJECT_API.md](PROJECT_API.md)ã€‚

è¯·å‚è€ƒå®Œæ•´æ–‡æ¡£ï¼š
- [å®Œæ•´ API å‚è€ƒ](PROJECT_API.md)
- [è®¤è¯](AUTHENTICATION.md)
- [ç¤ºä¾‹](../examples/)
```

**æ¨è**: é€‰é¡¹ Aï¼ˆåˆ é™¤ç©ºæ–‡æ¡£ï¼‰

**æ—¶é—´ä¼°è®¡**: 1 å¤©
**æ”¶ç›Š**: å‡å°‘æ··ä¹±ï¼Œæ”¹å–„æ–‡æ¡£å¯¼èˆª

---

#### 13. **å¢åŠ ç±»å‹æ³¨è§£è¦†ç›–ç‡**

**å½“å‰çŠ¶æ€**: éƒ¨åˆ†æ–‡ä»¶æœ‰ç±»å‹æ³¨è§£ï¼Œä½†è¦†ç›–ä¸å®Œæ•´

**ç›®æ ‡**: è¾¾åˆ° 80%+ çš„ç±»å‹æ³¨è§£è¦†ç›–ç‡

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ mypy æ£€æŸ¥ç±»å‹
# pyproject.toml
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true  # è¦æ±‚æ‰€æœ‰å‡½æ•°éƒ½æœ‰ç±»å‹æ³¨è§£
disallow_incomplete_defs = true
check_untyped_defs = true
no_implicit_optional = true

# ç¤ºä¾‹ï¼šä¸ºç°æœ‰ä»£ç æ·»åŠ ç±»å‹æ³¨è§£
from typing import List, Dict, Optional, Union, TypeVar, Generic

T = TypeVar('T')

class Result(Generic[T]):
    """ç±»å‹å®‰å…¨çš„ç»“æœåŒ…è£…å™¨"""

    def __init__(self, value: Optional[T] = None, error: Optional[str] = None):
        self.value = value
        self.error = error

    def is_ok(self) -> bool:
        return self.error is None

    def unwrap(self) -> T:
        if self.error:
            raise ValueError(self.error)
        return self.value  # type: ignore

# ä¸ºå‡½æ•°æ·»åŠ ç±»å‹æ³¨è§£
async def generate_payload(
    protocol: str,
    target: str,
    options: Optional[Dict[str, Any]] = None
) -> Result[PayloadModel]:
    """
    ç”Ÿæˆæµ‹è¯•è´Ÿè½½

    Args:
        protocol: åè®®ç±»å‹
        target: ç›®æ ‡åœ°å€
        options: å¯é€‰é…ç½®

    Returns:
        Result[PayloadModel]: åŒ…å«ç”Ÿæˆçš„è´Ÿè½½æˆ–é”™è¯¯
    """
    try:
        payload = await payload_generator.generate(protocol, target, options)
        return Result(value=payload)
    except Exception as e:
        return Result(error=str(e))

# ä½¿ç”¨ Protocol å®šä¹‰æ¥å£
from typing import Protocol

class LLMClient(Protocol):
    """LLM å®¢æˆ·ç«¯åè®®"""

    async def generate(self, prompt: str, **kwargs) -> str:
        """ç”Ÿæˆå“åº”"""
        ...

    async def embed(self, text: str) -> List[float]:
        """ç”ŸæˆåµŒå…¥"""
        ...

def process_with_llm(client: LLMClient, text: str) -> str:
    """ä½¿ç”¨ä»»ä½•ç¬¦åˆåè®®çš„ LLM å®¢æˆ·ç«¯"""
    return await client.generate(text)
```

**å®æ–½æ­¥éª¤**:
1. å®‰è£… mypy: `pip install mypy`
2. é…ç½® mypyï¼ˆpyproject.tomlï¼‰
3. è¿è¡Œ `mypy src --show-error-codes`
4. é€ä¸ªä¿®å¤é”™è¯¯
5. æ·»åŠ åˆ° pre-commit hooks

**æ—¶é—´ä¼°è®¡**: 1-2 å‘¨ï¼ˆå¯ä»¥æ¸è¿›å¼è¿›è¡Œï¼‰
**æ”¶ç›Š**: æ›´æ—©å‘ç°ç±»å‹é”™è¯¯ï¼Œæ›´å¥½çš„ IDE æ”¯æŒ

---

#### 14. **æ·»åŠ ä»£ç å¤æ‚åº¦æ£€æŸ¥**

**é—®é¢˜**: å¤šä¸ªå‡½æ•°è¶…è¿‡ 50 è¡Œï¼Œåœˆå¤æ‚åº¦è¿‡é«˜

**ä¿®å¤æ–¹æ¡ˆ**:
```bash
# å®‰è£… radonï¼ˆä»£ç å¤æ‚åº¦å·¥å…·ï¼‰
pip install radon

# æ£€æŸ¥åœˆå¤æ‚åº¦
radon cc src -a -nb

# æ£€æŸ¥å¯ç»´æŠ¤æ€§æŒ‡æ•°
radon mi src -nb

# æ·»åŠ åˆ° pre-commit
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: radon-cc
        name: Check cyclomatic complexity
        entry: radon cc
        args: ['--min', 'C', '--max', 'F']  # è­¦å‘Š C çº§åŠä»¥ä¸Š
        language: system
        types: [python]
```

**é‡æ„é«˜å¤æ‚åº¦å‡½æ•°çš„ç¤ºä¾‹**:
```python
# é‡æ„å‰ï¼šåœˆå¤æ‚åº¦ = 15
def process_payload(payload, options):
    if payload.protocol == "http":
        if options.get("method") == "GET":
            if options.get("params"):
                # ... 10 è¡Œä»£ç 
            else:
                # ... 8 è¡Œä»£ç 
        elif options.get("method") == "POST":
            # ... 15 è¡Œä»£ç 
    elif payload.protocol == "coap":
        # ... 20 è¡Œä»£ç 
    # ... æ›´å¤šæ¡ä»¶

# é‡æ„åï¼šä½¿ç”¨ç­–ç•¥æ¨¡å¼ï¼Œåœˆå¤æ‚åº¦ = 3
class PayloadProcessor(ABC):
    @abstractmethod
    async def process(self, payload, options):
        pass

class HttpGetProcessor(PayloadProcessor):
    async def process(self, payload, options):
        if options.get("params"):
            return await self._process_with_params(payload, options)
        return await self._process_without_params(payload, options)

class HttpPostProcessor(PayloadProcessor):
    async def process(self, payload, options):
        return await self._process_post(payload, options)

class CoapProcessor(PayloadProcessor):
    async def process(self, payload, options):
        return await self._process_coap(payload, options)

processors = {
    ("http", "GET"): HttpGetProcessor(),
    ("http", "POST"): HttpPostProcessor(),
    ("coap", None): CoapProcessor(),
}

async def process_payload(payload, options):
    key = (payload.protocol, options.get("method"))
    processor = processors.get(key)
    if not processor:
        raise ValueError(f"No processor for {key}")
    return await processor.process(payload, options)
```

**æ—¶é—´ä¼°è®¡**: 2-3 å‘¨ï¼ˆæ¸è¿›å¼é‡æ„ï¼‰
**æ”¶ç›Š**: æ›´æ˜“ç†è§£å’Œç»´æŠ¤çš„ä»£ç 

---

### ğŸŸ¢ P3 - æŠ€æœ¯å€ºåŠ¡ï¼ˆé•¿æœŸæ”¹è¿›ï¼‰

#### 15. **å®æ–½ä¾èµ–æ³¨å…¥**

**ç›®æ ‡**: å‡å°‘ç¡¬ç¼–ç ä¾èµ–ï¼Œæé«˜å¯æµ‹è¯•æ€§

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ dependency-injector åº“
from dependency_injector import containers, providers
from dependency_injector.wiring import Provide, inject

class Container(containers.DeclarativeContainer):
    """ä¾èµ–æ³¨å…¥å®¹å™¨"""

    config = providers.Configuration()

    # ç¼“å­˜
    cache_backend = providers.Singleton(
        MemoryCacheBackend,
        max_size=config.cache.max_size
    )

    cache_manager = providers.Singleton(
        UnifiedCacheManager,
        backend=cache_backend,
        namespace="hyfuzz"
    )

    # LLM æœåŠ¡
    llm_client = providers.Singleton(
        OllamaClient,
        base_url=config.llm.base_url
    )

    embedding_provider = providers.Singleton(
        OllamaEmbeddingProvider,
        model=config.llm.embedding_model
    )

    embedding_manager = providers.Singleton(
        EmbeddingManager,
        provider=embedding_provider
    )

    llm_service = providers.Singleton(
        LLMService,
        client=llm_client,
        cache=cache_manager,
        embeddings=embedding_manager
    )

    # çŸ¥è¯†åº“
    knowledge_db = providers.Singleton(
        VulnerabilityDB,
        cache=cache_manager
    )

    # API å¤„ç†å™¨
    fuzzing_handlers = providers.Factory(
        FuzzingHandlers,
        llm_service=llm_service,
        knowledge_db=knowledge_db
    )

# ä½¿ç”¨ä¾èµ–æ³¨å…¥
@inject
async def start_fuzzing_campaign(
    request: Request,
    llm_service: LLMService = Provide[Container.llm_service],
    knowledge_db: VulnerabilityDB = Provide[Container.knowledge_db]
):
    """å¯åŠ¨æ¨¡ç³Šæµ‹è¯•ï¼ˆä¾èµ–è‡ªåŠ¨æ³¨å…¥ï¼‰"""
    vulnerabilities = await knowledge_db.search(request.target)
    payloads = await llm_service.generate_payloads(vulnerabilities)
    return payloads

# ä¸»ç¨‹åº
def main():
    container = Container()
    container.config.from_yaml("config/config.yaml")
    container.wire(modules=[__name__])

    # ä¾èµ–å·²ç»é…ç½®å¥½ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
    asyncio.run(start_fuzzing_campaign(request))
```

**æ—¶é—´ä¼°è®¡**: 2 å‘¨
**æ”¶ç›Š**: æ›´å®¹æ˜“æµ‹è¯•ï¼Œæ›´çµæ´»çš„é…ç½®

---

#### 16. **æ·»åŠ æ€§èƒ½ç›‘æ§å’Œ APM**

**ç›®æ ‡**: å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ OpenTelemetry
from opentelemetry import trace, metrics
from opentelemetry.exporter.prometheus import PrometheusMetricReader
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger import JaegerExporter

# è®¾ç½®è¿½è¸ª
trace.set_tracer_provider(TracerProvider())
jaeger_exporter = JaegerExporter(
    agent_host_name="localhost",
    agent_port=6831,
)
trace.get_tracer_provider().add_span_processor(
    BatchSpanProcessor(jaeger_exporter)
)

# è®¾ç½®æŒ‡æ ‡
metric_reader = PrometheusMetricReader()
metrics.set_meter_provider(MeterProvider(metric_readers=[metric_reader]))

# è‡ªåŠ¨ instrument FastAPI
FastAPIInstrumentor.instrument_app(app)

# æ‰‹åŠ¨è¿½è¸ª
tracer = trace.get_tracer(__name__)
meter = metrics.get_meter(__name__)

# åˆ›å»ºè‡ªå®šä¹‰æŒ‡æ ‡
payload_generation_time = meter.create_histogram(
    name="payload_generation_time",
    description="Time to generate payloads",
    unit="ms"
)

llm_request_counter = meter.create_counter(
    name="llm_requests_total",
    description="Total LLM requests"
)

@tracer.start_as_current_span("generate_payload")
async def generate_payload(protocol: str):
    """ç”Ÿæˆè´Ÿè½½ï¼ˆå¸¦è¿½è¸ªï¼‰"""
    start = time.time()

    try:
        # è®°å½• LLM è¯·æ±‚
        llm_request_counter.add(1, {"protocol": protocol})

        # ç”Ÿæˆè´Ÿè½½
        payload = await llm_service.generate(protocol)

        # è®°å½•ç”Ÿæˆæ—¶é—´
        duration = (time.time() - start) * 1000
        payload_generation_time.record(duration, {"protocol": protocol})

        return payload
    except Exception as e:
        # è®°å½•é”™è¯¯
        trace.get_current_span().set_status(
            trace.Status(trace.StatusCode.ERROR, str(e))
        )
        raise
```

**æ—¶é—´ä¼°è®¡**: 1 å‘¨
**æ”¶ç›Š**: å¯è§‚æµ‹æ€§ï¼Œæ€§èƒ½ç“¶é¢ˆè¯†åˆ«

---

#### 17. **å®æ–½ API ç‰ˆæœ¬æ§åˆ¶**

**ç›®æ ‡**: æ”¯æŒ API å‘åå…¼å®¹

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# src/api/versioning.py
from fastapi import APIRouter, Request
from typing import Callable

class APIVersion:
    """API ç‰ˆæœ¬ç®¡ç†"""

    def __init__(self, major: int, minor: int):
        self.major = major
        self.minor = minor

    def __str__(self):
        return f"v{self.major}.{self.minor}"

    def __lt__(self, other):
        return (self.major, self.minor) < (other.major, other.minor)

class VersionedAPI:
    """ç‰ˆæœ¬åŒ–çš„ API è·¯ç”±å™¨"""

    def __init__(self, app: FastAPI):
        self.app = app
        self.versions = {}

    def add_version(self, version: APIVersion, router: APIRouter):
        """æ·»åŠ  API ç‰ˆæœ¬"""
        self.versions[version] = router
        self.app.include_router(
            router,
            prefix=f"/api/{version}"
        )

    def deprecated(self, version: APIVersion, sunset_date: str):
        """æ ‡è®°ç‰ˆæœ¬ä¸ºå¼ƒç”¨"""
        @self.app.middleware("http")
        async def add_deprecation_header(request: Request, call_next):
            response = await call_next(request)
            if request.url.path.startswith(f"/api/{version}"):
                response.headers["Deprecation"] = "true"
                response.headers["Sunset"] = sunset_date
            return response

# ä½¿ç”¨ç¤ºä¾‹
from fastapi import APIRouter

# V1 API
v1_router = APIRouter()

@v1_router.post("/fuzzing/start")
async def start_fuzzing_v1(request: FuzzingRequestV1):
    """V1 APIï¼ˆæ—§æ ¼å¼ï¼‰"""
    pass

# V2 API
v2_router = APIRouter()

@v2_router.post("/fuzzing/start")
async def start_fuzzing_v2(request: FuzzingRequestV2):
    """V2 APIï¼ˆæ–°æ ¼å¼ï¼Œæ”¯æŒæ›´å¤šé€‰é¡¹ï¼‰"""
    pass

# ä¸»åº”ç”¨
app = FastAPI()
api = VersionedAPI(app)

api.add_version(APIVersion(1, 0), v1_router)
api.add_version(APIVersion(2, 0), v2_router)
api.deprecated(APIVersion(1, 0), "2025-12-31")
```

**æ—¶é—´ä¼°è®¡**: 1 å‘¨
**æ”¶ç›Š**: API æ¼”è¿›çš„çµæ´»æ€§

---

## ğŸ“Š æ”¹è¿›æ•ˆæœé¢„æµ‹

å®æ–½è¿™äº›æ”¹è¿›åï¼Œé¢„æœŸçš„ç³»ç»Ÿæ”¹è¿›ï¼š

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | æ”¹å–„å¹…åº¦ |
|------|------|------|---------|
| å®‰å…¨æ¼æ´ | 11 ä¸ª | 0 ä¸ª | 100% |
| API å“åº”æ—¶é—´ | 10-20s | 1-3s | 3-10x |
| ç¼“å­˜å‘½ä¸­ç‡ | ~30% | 80%+ | 2.7x |
| å†…å­˜ç¨³å®šæ€§ | æŒç»­å¢é•¿ | ç¨³å®š | âœ“ |
| ä»£ç è¦†ç›–ç‡ | æœªçŸ¥ | 80%+ | - |
| ç±»å‹æ³¨è§£è¦†ç›– | ~40% | 80%+ | 2x |
| åœˆå¤æ‚åº¦ | 15+ | <10 | æ”¹å–„ |
| æ–‡æ¡£å®Œæ•´æ€§ | 70% | 95%+ | 25% |

---

## ğŸ“… å®æ–½æ—¶é—´è¡¨

### ç¬¬ 1 å‘¨ï¼šå…³é”®å®‰å…¨ä¿®å¤
- [ ] ç§»é™¤ Pickle ååºåˆ—åŒ–
- [ ] ä¿®å¤ç¡¬ç¼–ç å¯†é’¥
- [ ] ä¿®å¤ä¸å®‰å…¨çš„åŠ¨æ€å¯¼å…¥
- [ ] æ·»åŠ å…¨å±€å¼‚å¸¸å¤„ç†

### ç¬¬ 2-3 å‘¨ï¼šæ€§èƒ½ä¼˜åŒ–
- [ ] ä¿®å¤å†…å­˜æ³„æ¼
- [ ] å¹¶è¡ŒåŒ– CoT é“¾ç”Ÿæˆ
- [ ] ä¼˜åŒ–ç¼“å­˜ç­–ç•¥
- [ ] æ·»åŠ è¶…æ—¶ä¿æŠ¤

### ç¬¬ 4-6 å‘¨ï¼šä»£ç è´¨é‡
- [ ] é‡æ„ RouteHandlers
- [ ] åˆå¹¶ embedding_manager
- [ ] ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿ
- [ ] æ¸…ç†æ–‡æ¡£

### ç¬¬ 7-10 å‘¨ï¼šç±»å‹å®‰å…¨
- [ ] æ·»åŠ ç±»å‹æ³¨è§£
- [ ] é…ç½® mypy
- [ ] æ·»åŠ å¤æ‚åº¦æ£€æŸ¥

### ç¬¬ 11-14 å‘¨ï¼šæ¶æ„æ”¹è¿›
- [ ] å®æ–½ä¾èµ–æ³¨å…¥
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§
- [ ] API ç‰ˆæœ¬æ§åˆ¶

---

## ğŸ”§ å¼€å‘å·¥å…·æ¨è

### ä»£ç è´¨é‡å·¥å…·
```bash
# å®‰è£…å¼€å‘å·¥å…·
pip install \
    black \          # ä»£ç æ ¼å¼åŒ–
    isort \          # import æ’åº
    mypy \           # ç±»å‹æ£€æŸ¥
    ruff \           # å¿«é€Ÿ linter
    bandit \         # å®‰å…¨æ£€æŸ¥
    radon \          # å¤æ‚åº¦åˆ†æ
    pytest-cov \     # æµ‹è¯•è¦†ç›–ç‡
    pre-commit       # Git hooks

# é…ç½® pre-commit
cat > .pre-commit-config.yaml <<EOF
repos:
  - repo: https://github.com/psf/black
    rev: 24.0.0
    hooks:
      - id: black

  - repo: https://github.com/pycqa/isort
    rev: 5.13.0
    hooks:
      - id: isort

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.0
    hooks:
      - id: ruff

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.6
    hooks:
      - id: bandit
        args: ['-r', 'src']
EOF

# å®‰è£… hooks
pre-commit install
```

### CI/CD é›†æˆ
```yaml
# .github/workflows/quality.yml
name: Code Quality

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt

      - name: Run tests with coverage
        run: |
          pytest --cov=src --cov-report=xml --cov-report=html

      - name: Upload coverage
        uses: codecov/codecov-action@v3

      - name: Type check with mypy
        run: mypy src

      - name: Security check with bandit
        run: bandit -r src

      - name: Complexity check
        run: |
          radon cc src -a -nb
          radon mi src -nb
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®‰å…¨æœ€ä½³å®è·µ
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [Python Security Best Practices](https://python.readthedocs.io/en/stable/library/security_warnings.html)
- [Bandit Documentation](https://bandit.readthedocs.io/)

### æ€§èƒ½ä¼˜åŒ–
- [Python asyncio Documentation](https://docs.python.org/3/library/asyncio.html)
- [FastAPI Performance](https://fastapi.tiangolo.com/advanced/async-sql-databases/)
- [Python Memory Management](https://docs.python.org/3/c-api/memory.html)

### ä»£ç è´¨é‡
- [PEP 8 Style Guide](https://peps.python.org/pep-0008/)
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- [Clean Code in Python](https://github.com/zedr/clean-code-python)

### æ¶æ„è®¾è®¡
- [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- [Python Dependency Injection](https://python-dependency-injector.ets-labs.org/)
- [API Design Best Practices](https://swagger.io/resources/articles/best-practices-in-api-design/)

---

## âœ… æ£€æŸ¥æ¸…å•

### å®‰å…¨æ£€æŸ¥
- [ ] æ²¡æœ‰ä½¿ç”¨ pickle ååºåˆ—åŒ–
- [ ] æ‰€æœ‰å¯†é’¥ä»ç¯å¢ƒå˜é‡è¯»å–
- [ ] ä½¿ç”¨å®‰å…¨çš„éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆsecrets æ¨¡å—ï¼‰
- [ ] è¾“å…¥éªŒè¯å’Œæ¸…ç†
- [ ] SQL æ³¨å…¥é˜²æŠ¤
- [ ] XSS é˜²æŠ¤
- [ ] CSRF é˜²æŠ¤

### æ€§èƒ½æ£€æŸ¥
- [ ] æ²¡æœ‰å†…å­˜æ³„æ¼
- [ ] å¼‚æ­¥æ“ä½œæœ‰è¶…æ—¶
- [ ] ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- [ ] æ•°æ®åº“è¿æ¥æ± 
- [ ] æ‰¹é‡æ“ä½œä¼˜åŒ–
- [ ] èµ„æºæ­£ç¡®é‡Šæ”¾

### ä»£ç è´¨é‡æ£€æŸ¥
- [ ] é€šè¿‡ mypy ç±»å‹æ£€æŸ¥
- [ ] é€šè¿‡ ruff/flake8 linting
- [ ] ä»£ç æ ¼å¼åŒ–ï¼ˆblackï¼‰
- [ ] Import æ’åºï¼ˆisortï¼‰
- [ ] å¤æ‚åº¦ < 10ï¼ˆradonï¼‰
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%

### æ–‡æ¡£æ£€æŸ¥
- [ ] README å®Œæ•´
- [ ] API æ–‡æ¡£æ›´æ–°
- [ ] ä»£ç æ³¨é‡Šæ¸…æ™°
- [ ] Docstring å®Œæ•´
- [ ] å˜æ›´æ—¥å¿—æ›´æ–°
- [ ] æ²¡æœ‰ç©ºæ–‡æ¡£æ–‡ä»¶

---

## ğŸ¤ è´¡çŒ®

æ”¹è¿›å»ºè®®å’Œè´¡çŒ®ï¼š
1. åˆ›å»º Issue è®¨è®ºæ”¹è¿›æ–¹æ¡ˆ
2. Fork ä»“åº“
3. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
4. æäº¤ Pull Request
5. ä»£ç å®¡æŸ¥
6. åˆå¹¶åˆ°ä¸»åˆ†æ”¯

---

## ğŸ“ ç‰ˆæœ¬å†å²

- **v1.0.0** (2025-11-11): åˆå§‹æ”¹è¿›å»ºè®®æŠ¥å‘Š
  - å…¨é¢ä»£ç å®¡æŸ¥
  - è¯†åˆ« 62 ä¸ªæ”¹è¿›ç‚¹
  - æä¾›è¯¦ç»†ä¿®å¤æ–¹æ¡ˆ

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»ï¼š
- åˆ›å»º GitHub Issue
- é‚®ä»¶ï¼š[é¡¹ç›®ç»´æŠ¤è€…é‚®ç®±]

---

**æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„æ”¹è¿›å»ºè®®æŠ¥å‘Šï¼Œå»ºè®®æŒ‰ç…§ä¼˜å…ˆçº§é€æ­¥å®æ–½ã€‚ä¸è¦è¯•å›¾ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰æ”¹è¿›ï¼Œè¿™æ ·å¯èƒ½ä¼šå¼•å…¥æ–°çš„é—®é¢˜ã€‚é‡‡ç”¨æ¸è¿›å¼ã€è¿­ä»£å¼çš„æ–¹æ³•ï¼Œæ¯æ¬¡ä¸“æ³¨äºä¸€ä¸ªä¼˜å…ˆçº§çš„æ”¹è¿›ã€‚
